%----------------------------------------------------------------------------------------
%	ANALISI DI DEPLOYMENT SU LARGA SCALA
%----------------------------------------------------------------------------------------

\section{Analisi di deployment su larga scala}

In questa sezione va discussa, eventualmente con l'ausilio di opportuni diagrammi (componenti, deployment), l'evoluzione del progetto presentato immaginando che venga adottato su larga scala. I dettagli qui esposti devono quindi astrarre dalle specifiche dell'elaborato qualora l'implementazione sia stata focalizzata su uno scenario isolato.\\

A titolo d’esempio, qualora applicabile, devono essere evidenziate le criticità che si potrebbero incontrare e devono essere proposte soluzioni tipiche in contesti di \textit{cloud architecture} per garantire un'adeguata \textit{resilienza}, in termini di \textit{availability} e \textit{scalability} del sistema.\\


Vincoli circa la lunghezza della sezione (escluse didascalie, tabelle, testo nelle immagini, schemi):

\vspace{1cm}
\begin{tabular}{l|rr}
 & Numero minimo di battute & Numero massimo di battute \\
 \hline
 1 componente & 3000 & 6000 \\
 2 componenti & 4500 & 9000 \\
 3 componenti & 6000 & 12000 \\
 \hline
\end{tabular}

Il paradigma a microservizi da noi adottato si adatta perfettamente al deployment su larga scala.
Il progetto è stato fin da subito pensato per l'esecuzione in cloud, utilizzando appieno gli Amazon Web Services anche durante lo sviluppo locale.

Di seguito descriveremo in prima fase l'architettura adottata per il deployment, 
passeremo poi ad illustrare come viene praticamente eseguito il deployment sui vari ambienti (locale, staging e production), 
ed infine quali sono i costi totali del sistema. 

\subsection{Architettura Cloud}

Il progetto Ecotrip si basa sul raccogliere dati da una moltitudine di camere di una moltitudine di hotel, 
analizzarli ed aggregarli al fine di calcolare punteggi da fornire ad una moltitudine di utenti (visitatori e albergatori).

In prima battuta però Ecotrip verrà adottato da un singolo Hotel, è chiara quindi l'esigenza di un'architettura di deployment 
che consenta di partire con costi ridotti e che permetta la scalabilità al bisogno.

Per ottenere questo abbiamo impiegato il paradigma Serverless per le componenti che richiedono una forte scalabilità, 
come il caricamento e lo stoccaggio dei dati, l'elaborazione e la fornitura verso gli utenti finali. 
Serverless significa impiegare servizi Cloud che scalano in automatico all'occorrenza, senza alcuna pianificazione prestabilita o intervento umano.

In Figura XXX mostriamo l'achitettura implementata utilizzando i componenti resi da AWS.

Per quanto concerne lo stoccaggio di tutti i dati di Ecotrip si è scelto di usare unicamente DynamoDB che è in grado di scalare automaticamente sia per 
quello che concerne la quantità di dati che per il numero di richieste al secondo. 

AWS IoT Core si occupa di interfacciarsi con le centraline fisiche, gestire il loro stato, ricevere i messaggi MQTT e stoccarli attraverso un opportuna regola su DynamoDB.

EC2: si occupa di fornire la Rest API di "Administration". 
Il traffico richiesto per questo componente è relativamente basso in quanto la API "Administration" è soprattutto utilizzata dal pannello di controllo, 
e si assume che vengano fatte richieste contemporanee da al massimo un utente per hotel, 
oltre ai vistatori che attraverso le app ricevono limitate informazioni sull'hotel (il nome) e il pernottamento corrente.
Per questo, in questa prima fase, si è scelto di non dotare il servizio API di scaling automatico tramite l'aggiunta di un load balancer 
o tramite l'impiego di sistemi più avanzati come ECS / kubernetees.
La configurazione AWS adottata per la EC2 è una XXX-medium-xx, più che sufficiente per gestire un certo numero di un hotel.
Il futuro potrebbe essere sostituire la EC2 con un AWS API Gateway che consente la completa scalabilità on demand tramite l'impiego di AWS Lambda.

Per quanto riguarda il deployment del frontend del pannello di controllo e della web app per i visitatori, che ricordiamo essere entrambe single page application, 
sono stati impiegati semplicemente dei bucket S3. 

E' stata poi abilitata una CDN (Content Delivery Network) che riceve le richieste dei browser e le inoltra, a seconda della tipologia, alla EC2 oppure ad S3.
La CDN è un servizio di caching dei dati distribuito su diversi nodi, consente di ridurre il carico sui server e contemporaneamente ridurre la latenza di servizio: 
i nodi infatti sono dislocati sul territorio in modo da essere fisicamente vicini all'utenza.

La generazione del token per i visiatori del microservizio "Guest Authorization" avviene su una AWS Lambda, questa si attiva alla ricezione di un messaggio inviato da "Administration" attraverso il servizio AWS QUEUE.

Per l'elaborazione dei dati da parte di "Data Elaboration" è stata impiegata un'altra Lambda che si attiva periodicamente ogni 5 secondi e dopo aver eseguito i calcoli li memorizza su un apposta tabella DynamoDB.
Attualmente i dati da elaborare vengono processati da un unica istanza della Lambda, ma è possibile strutturale il sistema in modo che ogni hotel avvii la sua istanza di lambda periodicamente 
per processare unicamente i suoi dati: questo consente la totale scalabilità computazionale anche per quanto riguarda questo servizio che è il più critico ed oneroso in termini di costo di CPU.
La fornitura dei dati elaborati, come i consumi di un pernottamento o il punteggio sostenibilità richiesti dai visitatori o almbergatori, avviene attraverso una REST API realizzata con AWS Gateway: 
servizio di Amazon che permette ad una API di abbracciare in pieno il paradigma Serverless e quindi piena scalabilità on-demand.

Altro??

\subsection{Ambienti di deployment}

Il deployment è un aspetto cruciale per questo tipo di progetto, per questo ci siamo concentrati subito sul definire come lavorare e sviluppare in locale con i servizi cloud.

Abbiamo predisposto 3 ambienti: locale, staging e production.

Ciascun componente del team ha la possiblità tramite un unico comando di avviare una copia dell'ambiente di production a suo uso personale, 
al fine di avviare e testare i vari programmi/servizi durante lo sviluppo.

3) ---> perchè utilizzare SAM (Cloud Formation), differenze tra i due, scrivere l'infrastruttura è figo rispetto a cliccare la ui di aws
A tal fine tutta l'archiettura descritta in precedenza viene messa in piedi grazie all'utilizzo di SAM e cloud formation di Amazon.
In pratica è tutto codificato in file YAML etc etc.

Alcuni componenti per l'ambiente locale non vengono istanziati, è il caso della EC2 che viene sostituita dall'avvio in locale di un container docker per realizzare il servizio API "Administration".

L'ambiente di "Staging" consente invece di testate tutto online senza interferire con i dati e l'ambiente di "production".

\subsection{Analisi dei costi}

Abbiamo raccolto i costi di fornitura del servizio cloud per singola stanza.


\newpage